{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1838ff",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f824a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd840590",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a080fa",
   "metadata": {},
   "source": [
    "### Finance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_finance(ticker, start_date=\"2018-01-01\", end_date=\"2023-04-04\"): # create_multi_df\n",
    "    # Load data\n",
    "    tickerData = yf.Ticker(ticker)\n",
    "    tickerDF = tickerData.history(period=\"1d\", start=start_date, end=end_date)\n",
    "\n",
    "    # cut some variables\n",
    "    tickerDF = tickerDF.drop(\"Dividends\", axis=1)\n",
    "    tickerDF = tickerDF.drop(\"Stock Splits\", axis=1)\n",
    "\n",
    "    # add control variables\n",
    "    tickerDataDJI = yf.Ticker('^DJI')\n",
    "    tickerDFDJI = tickerDataDJI.history(period='1d', start=start_date, end=end_date)\n",
    "    tickerDFDJI['DJI'] = tickerDFDJI['Close']\n",
    "    tickerDF = pd.merge(tickerDF, tickerDFDJI['DJI'], left_index=True, right_index=True)\n",
    "\n",
    "    # delete na rows\n",
    "    tickerDF = tickerDF.dropna()\n",
    "    \n",
    "    return tickerDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40dad7f",
   "metadata": {},
   "source": [
    "### Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e66890",
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_path = \"output_FinBert_final.xlsx\"\n",
    "textblob_path = \"output_TextBlob.xlsx\"\n",
    "vader_path = \"output_VADER.xlsx\"\n",
    "flair_path = \"Result_Flair_v1.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24942954",
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert = pd.read_excel(finbert_path, index_col=0)\n",
    "finbert = finbert.drop([\"Neutral\"], axis=1) # avoid multicollinearity\n",
    "\n",
    "textblob = pd.read_excel(textblob_path, index_col=0)\n",
    "\n",
    "vader = pd.read_excel(vader_path, index_col=0)\n",
    "vader = vader.drop([\"vader_neu\"], axis=1) # avoid multicollinearity\n",
    "\n",
    "flair = pd.read_excel(flair_path, index_col=0)\n",
    "flair = flair.reset_index()\n",
    "flair = flair.rename(columns={\"Date\":\"date\", \"Stock name\":\"stock_name\", \"Report type\":\"report_type\"}) # fix typo\n",
    "flair[\"flair_sentiment\"] = flair.apply(lambda x: x[\"Sentiment score\"] if x[\"Sentiment value\"] == \"POSITIVE\" else 1-x[\"Sentiment score\"], axis=1)\n",
    "flair = flair.drop([\"Sentiment score\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_text(df, feature_lst, ticker):\n",
    "    df_ticker = df[df[\"stock_name\"]==ticker]\n",
    "    df_ticker = df_ticker.groupby([\"date\", \"report_type\"], as_index=False).mean()\n",
    "\n",
    "    df_ticker.set_index(\"date\", inplace=True)\n",
    "    df_ticker = df_ticker.drop([\"report_type\"], axis=1)\n",
    "\n",
    "    return df_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1131e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_all_text(ticker):\n",
    "    finbert_ticker = prep_text(finbert, [\"Positive\", \"Negative\"], ticker)\n",
    "    textblob_ticker = prep_text(textblob, [\"tb_polarity\", \"tb_subjectivity\"], ticker)\n",
    "    vader_ticker = prep_text(vader, [\"vader_neg\", \"vader_pos\", \"vader_compound\"], ticker)\n",
    "    flair_ticker = prep_text(flair, [\"flair_sentiment\"], ticker)\n",
    "\n",
    "    text_ticker = pd.merge(finbert_ticker, textblob_ticker, left_index=True, right_index=True, how='outer')\n",
    "    text_ticker = pd.merge(text_ticker, vader_ticker, left_index=True, right_index=True, how='outer')\n",
    "    text_ticker = pd.merge(text_ticker, flair_ticker, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "    return text_ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd6e4a",
   "metadata": {},
   "source": [
    "### Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39644428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_all_feature(ticker):\n",
    "    fin_data = prep_finance(ticker)\n",
    "    text_data = prep_all_text(ticker)\n",
    "    fin_data.index = fin_data.index.strftime(\"%Y-%m-%d\")\n",
    "    text_data.index = text_data.index.strftime(\"%Y-%m-%d\")\n",
    "    res = pd.merge(fin_data, text_data, left_index=True, right_index=True, how=\"left\")\n",
    "    #\n",
    "    res.fillna(method='ffill', inplace=True)\n",
    "    res = res.dropna()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f29ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(stock, lookback):\n",
    "    data_raw = stock.to_numpy() \n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    test_set_size = int(np.round(0.1*data.shape[0]))\n",
    "    train_set_size = data.shape[0] - (test_set_size)\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900835a4",
   "metadata": {},
   "source": [
    "### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn) = self.gru(x, (h0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29420ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_inputs, train_targets, num_epochs, criterion, optimizer):\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_inputs)\n",
    "        loss = criterion(outputs, train_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_inputs, test_targets, criterion):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_inputs)\n",
    "        loss = criterion(outputs, test_targets)\n",
    "    return test_targets, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d4ca1",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b682ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 7\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = GRU(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80a306",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(model,num_epochs,criterion,optimizer,feature_lst):\n",
    "    company_name=[\"AAPL\", \"MSFT\", \"V\", \"UNH\", \"JPM\", \"JNJ\", \"WMT\", \"PG\", \"CVX\", \"HD\"]\n",
    "    output=[]\n",
    "    for i in range(len(company_name)):\n",
    "        data=prep_all_feature(company_name[i])\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        for col in data.columns:\n",
    "            if col==\"Close\":\n",
    "                data[col] = target_scaler.fit_transform(data[col].values.reshape(-1,1))\n",
    "            else:\n",
    "                data[col] = scaler.fit_transform(data[col].values.reshape(-1,1))\n",
    "        data=data[feature_lst]\n",
    "        lookback = 15 # choose sequence length\n",
    "        x_train, y_train, x_test, y_test = split_data(data, lookback)\n",
    "        x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "        x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "        y_train = y_train[:,0].reshape(-1,1)\n",
    "        y_test = y_test[:,0].reshape(-1,1)\n",
    "        y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "        y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "        train_gru=train(model, x_train, y_train_gru, num_epochs, criterion, optimizer)\n",
    "        eva_gru=evaluate(model, x_test, y_test_gru, criterion)\n",
    "        days = range(len(eva_gru[0]))\n",
    "        y1=target_scaler.inverse_transform(eva_gru[0])\n",
    "        y2=target_scaler.inverse_transform(eva_gru[1])\n",
    "        testScore = math.sqrt(mean_squared_error(y1.reshape(-1,1),y2.reshape(-1,1)))\n",
    "        output.append(testScore)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lst = [\"Positive\", \"Negative\", \"tb_polarity\", \"tb_subjectivity\", \"vader_neg\", \"vader_pos\", \"vader_compound\", \"flair_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output={}\n",
    "final_output[\"Stock\"]=[\"AAPL\", \"MSFT\", \"V\", \"UNH\", \"JPM\", \"JNJ\", \"WMT\", \"PG\", \"CVX\", \"HD\"]\n",
    "model = GRU(input_dim=6, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "final_output[\"Baseline\"] = result(model,num_epochs,criterion,optimizer,[\"Close\",\"Open\",\"High\",\"Low\",\"Volume\",\"DJI\"])\n",
    "model = GRU(input_dim=9, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "final_output[\"VADER\"] = result(model,num_epochs,criterion,optimizer,[\"Close\",\"Open\",\"High\",\"Low\",\"Volume\",\"DJI\",\"vader_neg\", \"vader_pos\", \"vader_compound\"])\n",
    "model = GRU(input_dim=8, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "final_output[\"Text Blob\"] = result(model,num_epochs,criterion,optimizer,[\"Close\",\"Open\",\"High\",\"Low\",\"Volume\",\"DJI\",\"tb_polarity\",\"tb_subjectivity\"])\n",
    "model = GRU(input_dim=8, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "final_output[\"FinBERT\"] = result(model,num_epochs,criterion,optimizer,[\"Close\",\"Open\",\"High\",\"Low\",\"Volume\",\"DJI\",\"Positive\", \"Negative\"])\n",
    "model = GRU(input_dim=7, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "final_output[\"Flair\"] = result(model,num_epochs,criterion,optimizer,[\"Close\",\"Open\",\"High\",\"Low\",\"Volume\",\"DJI\",\"flair_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df = pd.DataFrame(final_output)\n",
    "final_output_df.to_excel(\"GRU_stock_rmse.xlsx\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
