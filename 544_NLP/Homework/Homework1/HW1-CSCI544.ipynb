{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "[nltk_data] Downloading package wordnet to /Users/boom/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/boom/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/boom/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install bs4 # in case you don't have it installed\n",
    "# ! pip install contractions\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-a057dc4512f1>:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data.tsv', sep='\\t', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
      "0          US      1797882  R3I2DHQBR577SS  B001ANOOOE         2102612   \n",
      "1          US     18381298  R1QNE9NQFJC2Y4  B0016J22EQ       106393691   \n",
      "2          US     19242472  R3LIDG2Q4LJBAO  B00HU6UQAG       375449471   \n",
      "3          US     19551372  R3KSZHPAEVPEAL  B002HWS7RM       255651889   \n",
      "4          US     14802407   RAI2OIG50KZ43  B00SM99KWU       116158747   \n",
      "\n",
      "                                       product_title product_category  \\\n",
      "0  The Naked Bee Vitmin C Moisturizing Sunscreen ...           Beauty   \n",
      "1      Alba Botanica Sunless Tanning Lotion, 4 Ounce           Beauty   \n",
      "2          Elysee Infusion Skin Therapy Elixir, 2oz.           Beauty   \n",
      "3  Diane D722 Color, Perm And Conditioner Process...           Beauty   \n",
      "4  Biore UV Aqua Rich Watery Essence SPF50+/PA+++...           Beauty   \n",
      "\n",
      "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
      "0           5            0.0          0.0    N                 Y   \n",
      "1           5            0.0          0.0    N                 Y   \n",
      "2           5            0.0          0.0    N                 Y   \n",
      "3           5            0.0          0.0    N                 Y   \n",
      "4           5            0.0          0.0    N                 Y   \n",
      "\n",
      "                                     review_headline  \\\n",
      "0                                         Five Stars   \n",
      "1                          Thank you Alba Bontanica!   \n",
      "2                                         Five Stars   \n",
      "3                                         GOOD DEAL!   \n",
      "4  this soaks in quick and provides a nice base f...   \n",
      "\n",
      "                                         review_body review_date  \n",
      "0                   Love this, excellent sun block!!  2015-08-31  \n",
      "1  The great thing about this cream is that it do...  2015-08-31  \n",
      "2  Great Product, I'm 65 years old and this is al...  2015-08-31  \n",
      "3  I use them as shower caps & conditioning caps....  2015-08-31  \n",
      "4  This is my go-to daily sunblock. It leaves no ...  2015-08-31  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.tsv', sep='\\t', on_bad_lines='skip')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ['review_body', 'star_rating']]\n",
    "df['star_rating'] = pd.to_numeric(df['star_rating'], errors='coerce')\n",
    "df = df[~df['star_rating'].isna()]\n",
    "df['star_rating'] = df['star_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_body  star_rating\n",
      "0                   Love this, excellent sun block!!            5\n",
      "1  The great thing about this cream is that it do...            5\n",
      "2  Great Product, I'm 65 years old and this is al...            5\n",
      "3  I use them as shower caps & conditioning caps....            5\n",
      "4  This is my go-to daily sunblock. It leaves no ...            5\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[:, ['review_body', 'star_rating']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group ratings to 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_body  star_rating\n",
      "0                   Love this, excellent sun block!!            3\n",
      "1  The great thing about this cream is that it do...            3\n",
      "2  Great Product, I'm 65 years old and this is al...            3\n",
      "3  I use them as shower caps & conditioning caps....            3\n",
      "4  This is my go-to daily sunblock. It leaves no ...            3\n"
     ]
    }
   ],
   "source": [
    "mapping = {1: 1, 2: 1, 3: 2, 4: 3, 5: 3}\n",
    "df = df.replace({'star_rating': mapping})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### We form three classes and select 20000 reviews randomly from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               review_body  star_rating\n",
      "1294234  Handle provided had some rusted internal threa...            1\n",
      "4186939  MY WIFE SAYS THAT THIS REALLY WASNT USEFUL FOR...            1\n",
      "4493244  This came with no glue, and the gel was hard a...            1\n",
      "3048924  I bought this product because of all the 5-sta...            1\n",
      "4149821  i got this product expecting the wow factor, b...            1\n"
     ]
    }
   ],
   "source": [
    "r_state = 555\n",
    "list_sample = [df[df.star_rating == 1].sample(n=20000, random_state=r_state),\n",
    "            df[df.star_rating == 2].sample(n=20000, random_state=r_state),\n",
    "            df[df.star_rating == 3].sample(n=20000, random_state=r_state)]\n",
    "df_sample = pd.concat(list_sample)\n",
    "print(df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             review_body\n",
      "star_rating             \n",
      "1                  20000\n",
      "2                  20000\n",
      "3                  20000\n"
     ]
    }
   ],
   "source": [
    "print(df_sample.groupby('star_rating').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    review  stars\n",
      "1294234  handle provided had some rusted internal threa...      1\n",
      "4186939  my wife says that this really wasnt useful for...      1\n",
      "4493244  this came with no glue, and the gel was hard a...      1\n",
      "3048924  i bought this product because of all the 5-sta...      1\n",
      "4149821  i got this product expecting the wow factor, b...      1\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_sample.copy()\n",
    "df_clean.columns = ['review', 'stars']\n",
    "\n",
    "df_clean['review'] = df_clean['review'].apply(str.lower)\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    review  stars\n",
      "1294234  handle provided had some rusted internal threa...      1\n",
      "4186939  my wife says that this really wasnt useful for...      1\n",
      "4493244  this came with no glue, and the gel was hard a...      1\n",
      "3048924  i bought this product because of all the 5-sta...      1\n",
      "4149821  i got this product expecting the wow factor, b...      1\n"
     ]
    }
   ],
   "source": [
    "# remove HTML\n",
    "df_clean['review'] = df_clean['review'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "\n",
    "# remove URLs\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "\n",
    "df_clean['review'] = df_clean['review'].apply(remove_urls)\n",
    "print(df_clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform contractions on the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    review  stars\n",
      "1294234  handle provided had some rusted internal threa...      1\n",
      "4186939  my wife says that this really was not useful f...      1\n",
      "4493244  this came with no glue, and the gel was hard a...      1\n",
      "3048924  i bought this product because of all the 5-sta...      1\n",
      "4149821  i got this product expecting the wow factor, b...      1\n"
     ]
    }
   ],
   "source": [
    "def perform_contractions(text):\n",
    "    return ' '.join([contractions.fix(word) for word in text.split()])\n",
    "\n",
    "df_clean['review'] = df_clean['review'].apply(perform_contractions)\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    review  stars\n",
      "1294234  handle provided had some rusted internal threa...      1\n",
      "4186939  my wife says that this really was not useful f...      1\n",
      "4493244  this came with no glue  and the gel was hard a...      1\n",
      "3048924  i bought this product because of all the 5 sta...      1\n",
      "4149821  i got this product expecting the wow factor  b...      1\n"
     ]
    }
   ],
   "source": [
    "def remove_non_alpha_chars(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "\n",
    "df_clean['review'] = df_clean['review'].apply(remove_non_alpha_chars)\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    review  stars\n",
      "1294234  handle provided had some rusted internal threa...      1\n",
      "4186939  my wife says that this really was not useful f...      1\n",
      "4493244  this came with no glue and the gel was hard as...      1\n",
      "3048924  i bought this product because of all the 5 sta...      1\n",
      "4149821  i got this product expecting the wow factor bu...      1\n"
     ]
    }
   ],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "df_clean['review'] = df_clean['review'].apply(remove_extra_spaces)\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of reviews before and after data cleaning: 281.41571666666664, 273.19905\n"
     ]
    }
   ],
   "source": [
    "# printing average lengths before/after data cleaning\n",
    "print('Average length of reviews before and after data cleaning: ', \\\n",
    "      df_sample['review_body'].str.len().mean(), ', ', df_clean['review'].str.len().mean(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    review  stars\n",
      "1294234  handle provided rusted internal threading incl...      1\n",
      "4186939  wife says really useful nail polish plate rubb...      1\n",
      "4493244  came glue gel hard rock never buying product d...      1\n",
      "3048924  bought product 5 star ratings received wonderi...      1\n",
      "4149821  got product expecting wow factor found priced ...      1\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df_preproc = df_clean.copy()\n",
    "df_preproc['review'] = df_preproc['review'].apply(remove_stop_words)\n",
    "print(df_preproc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    review  stars\n",
      "1294234  handle provide rust internal threading include...      1\n",
      "4186939  wife say really useful nail polish plate rub s...      1\n",
      "4493244  come glue gel hard rock never buy product diss...      1\n",
      "3048924  buy product 5 star rating receive wonder produ...      1\n",
      "4149821  get product expect wow factor find price size ...      1\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(lemmatizer, text):\n",
    "    lemmatized_list = []\n",
    "    for word, pos_tag in nltk.pos_tag(text.split()):\n",
    "        if pos_tag.startswith('V'):\n",
    "            lemmatized_list.append(lemmatizer.lemmatize(word, 'v'))\n",
    "        elif pos_tag.startswith('J'):\n",
    "            lemmatized_list.append(lemmatizer.lemmatize(word, 'a'))\n",
    "        else:\n",
    "            lemmatized_list.append(lemmatizer.lemmatize(word))\n",
    "    return ' '.join(lemmatized_list)\n",
    "\n",
    "df_lemma = df_preproc.copy()\n",
    "df_lemma['review'] = df_lemma['review'].apply(lambda x: perform_lemmatization(lemmatizer, x))\n",
    "print(df_lemma.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of reviews before and after data preprocessing: 273.19905, 158.77876666666666\n"
     ]
    }
   ],
   "source": [
    "# printing average lengths before/after data preprocessing\n",
    "print('Average length of reviews before and after data preprocessing: ', \\\n",
    "      df_clean['review'].str.len().mean(), ', ', df_lemma['review'].str.len().mean(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "df_model = df_lemma.copy()\n",
    "tfidf = vectorizer.fit_transform(df_model['review'])\n",
    "df_X = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    00  000   01   02   03   04   05   06   07   08  ...  ziploc  ziplock  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "\n",
      "   zipper  zirconium  zit  zits  zombie  zone  zoom  zoya  \n",
      "0     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "1     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "2     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "3     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "4     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 10000 columns]\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_X.head())\n",
    "df_y = df_model['stars'].reset_index(drop=True)\n",
    "df_y = df_y.astype(int)\n",
    "print(df_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training/testing set - 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        00  000   01   02   03   04   05   06   07   08  ...  ziploc  ziplock  \\\n",
      "5521   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "38538  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "30253  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "45733  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "2593   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...      ...   \n",
      "39184  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "18365  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "33132  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "22889  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "10375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "\n",
      "       zipper  zirconium  zit  zits  zombie  zone  zoom  zoya  \n",
      "5521      0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "38538     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "30253     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "45733     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "2593      0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "...       ...        ...  ...   ...     ...   ...   ...   ...  \n",
      "39184     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "18365     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "33132     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "22889     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "10375     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "\n",
      "[48000 rows x 10000 columns]         00  000   01   02   03   04   05   06   07   08  ...  ziploc  ziplock  \\\n",
      "31788  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "16832  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "8267   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "55958  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "11472  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...      ...   \n",
      "5042   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "35683  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "52589  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "6437   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "33910  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0      0.0   \n",
      "\n",
      "       zipper  zirconium  zit  zits  zombie  zone  zoom  zoya  \n",
      "31788     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "16832     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "8267      0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "55958     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "11472     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "...       ...        ...  ...   ...     ...   ...   ...   ...  \n",
      "5042      0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "35683     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "52589     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "6437      0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "33910     0.0        0.0  0.0   0.0     0.0   0.0   0.0   0.0  \n",
      "\n",
      "[12000 rows x 10000 columns] 5521     1\n",
      "38538    2\n",
      "30253    2\n",
      "45733    3\n",
      "2593     1\n",
      "        ..\n",
      "39184    2\n",
      "18365    1\n",
      "33132    2\n",
      "22889    2\n",
      "10375    1\n",
      "Name: stars, Length: 48000, dtype: int64 31788    2\n",
      "16832    1\n",
      "8267     1\n",
      "55958    3\n",
      "11472    1\n",
      "        ..\n",
      "5042     1\n",
      "35683    2\n",
      "52589    3\n",
      "6437     1\n",
      "33910    2\n",
      "Name: stars, Length: 12000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=r_state, stratify=df_y)\n",
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_scores(clf, X_test, y_test, clf_name):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    dict_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    key_list = ['1', '2', '3', 'weighted avg']\n",
    "    report_name_list = ['(Class 1)', '(Class 2)', '(Class 3)', '(Average)']\n",
    "    for i, k in enumerate(key_list):\n",
    "        temp_report = dict_report[k]\n",
    "        precision = str(temp_report['precision'])\n",
    "        recall = str(temp_report['recall'])\n",
    "        f1_score = str(temp_report['f1-score'])\n",
    "        print('Precision, Recall, and f1-score for the testing split for ' + clf_name + ' ' + report_name_list[i] + ': ', \\\n",
    "             precision + ',' + recall + ',' + f1_score)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(penalty='elasticnet', random_state=555)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_perceptron = Perceptron(random_state=r_state, penalty='elasticnet')\n",
    "clf_perceptron.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, and f1-score for the testing split for Perceptron (Class 1):  0.6639344262295082,0.6075,0.6344647519582245\n",
      "Precision, Recall, and f1-score for the testing split for Perceptron (Class 2):  0.4931712191872085,0.74025,0.5919632147141144\n",
      "Precision, Recall, and f1-score for the testing split for Perceptron (Class 3):  0.8394691780821918,0.49025,0.6190025252525253\n",
      "Precision, Recall, and f1-score for the testing split for Perceptron (Average):  0.6655249411663028,0.6126666666666667,0.6151434973082881\n"
     ]
    }
   ],
   "source": [
    "report_scores(clf_perceptron, X_test, y_test, 'Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=50000, random_state=555)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_SVC = LinearSVC(random_state=r_state, multi_class='ovr', dual=True, max_iter=50000)\n",
    "clf_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, and f1-score for the testing split for SVM (Class 1):  0.6718175128771156,0.68475,0.6782221121703603\n",
      "Precision, Recall, and f1-score for the testing split for SVM (Class 2):  0.5754189944134078,0.54075,0.5575460755251966\n",
      "Precision, Recall, and f1-score for the testing split for SVM (Class 3):  0.7154178674351584,0.74475,0.7297893189612935\n",
      "Precision, Recall, and f1-score for the testing split for SVM (Average):  0.6542181249085607,0.65675,0.6551858355522835\n"
     ]
    }
   ],
   "source": [
    "report_scores(clf_SVC, X_test, y_test, 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, multi_class='ovr', random_state=555)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_logreg = LogisticRegression(random_state=r_state, multi_class='ovr', max_iter=5000)\n",
    "clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, and f1-score for the testing split for Logistic Regression (Class 1):  0.6900655817342726,0.71025,0.7000123198225946\n",
      "Precision, Recall, and f1-score for the testing split for Logistic Regression (Class 2):  0.5955862802446158,0.56,0.5772452003607782\n",
      "Precision, Recall, and f1-score for the testing split for Logistic Regression (Class 3):  0.7331392527899078,0.7555,0.744151686776656\n",
      "Precision, Recall, and f1-score for the testing split for Logistic Regression (Average):  0.6729303715895987,0.67525,0.6738030689866763\n"
     ]
    }
   ],
   "source": [
    "report_scores(clf_logreg, X_test, y_test, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, and f1-score for the testing split for Naive Bayes (Class 1):  0.6969292389853138,0.6525,0.6739832149774048\n",
      "Precision, Recall, and f1-score for the testing split for Naive Bayes (Class 2):  0.5639562529719448,0.593,0.5781135754326103\n",
      "Precision, Recall, and f1-score for the testing split for Naive Bayes (Class 3):  0.7135095085206223,0.72225,0.7178531494595601\n",
      "Precision, Recall, and f1-score for the testing split for Naive Bayes (Average):  0.6581316668259604,0.6559166666666667,0.6566499799565251\n"
     ]
    }
   ],
   "source": [
    "report_scores(clf_nb, X_test, y_test, 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://stackoverflow.com/questions/45999415/removing-html-tags-in-pandas\n",
    "- https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "- https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
